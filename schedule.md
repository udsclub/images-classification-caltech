Деадлайны/задачи что озвучивались
к 24.06(суббота):
- Скачать данные с kaggle или s3
- Проанализировать данные - распределения по классам, размеры изображений.
- Сделать простейший data handler на python который сможет привести изображения к одному размеру(путем масштабирования и/или обрезки) и сделать их удобными для обучения(one hot classes например)
- разбиваем данные на train/validation
- Берем какое-то простейшее решение и пытаемся потренировать и посмотреть какая будет точность. Так у нас будет baseline c чем дальше производить сравнения.

к 27.06(вторник):
- Перевести тренировку на нейронные сети(простейшая fully connected на несколько слоев)
- Начать тренировать батчами
- Если осталось время - попытаться разобраться что такое сверточные слои и начать использовать их

к 01.07(суббота):
- Сделать свою сеть уже на сверточных слоях
- Попробовать повысить точность при помощи различных вариантов, например:
  - BatchNormalization
  - Dropout
  - Resudial connections
  - Data aurmentation
- Попробуйте хоть несколько подходов что бы понять как они влияют на вашуархитектуру и подход
- Если совсем сдались и еще остлось время - начинаем заниматься transfer learning. Находим одну из известных сетей для images classification и пробуем файнтюнить ее под наш датасет.
